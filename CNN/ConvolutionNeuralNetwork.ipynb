{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1、卷积\n",
    "\n",
    "## 前向过程\n",
    "\n",
    "### Convolution概念\n",
    "\n",
    "既然叫卷积神经网络，那么就先了解这里的卷积是什么，对于卷积神经网络一般使用离散数据，离散形式的函数$f,g$卷积定义如下：\n",
    "\n",
    "$$(f*g)[n] = \\sum_{m=-\\infty}^{\\infty} f[m]g[n-m]$$\n",
    "\n",
    "而在卷积神经网络中使用的卷积则规定了卷积的范围不再是$[-\\infty, \\infty]$而是由被卷积数据size决定，假设有如下原始数据和卷积函数：\n",
    "\n",
    "原始数据：\n",
    "![](./data/image/conv1.jpg '原始数据')\n",
    "卷积函数：\n",
    "![](./data/image/conv2.jpg '卷积函数')\n",
    "单点卷积结果（即对应位置相乘再求和）：\n",
    "![](./data/image/conv3.jpg '单点卷积结果')\n",
    "卷积结果：\n",
    "![](./data/image/conv6.jpg '卷积结果')\n",
    "\n",
    "根据卷积过程我们可知，设原始数据为$(m,n)$，卷积函数为$(f,f)$，卷积步长为$s$，那么得到的卷积结果为$(floor(\\frac{m-f}{s}) + 1, floor(\\frac{n-f}{s}) + 1)$。(**在深度学习中卷积矩阵基本为方阵**)\n",
    "\n",
    "### Padding\n",
    "\n",
    "可以看到卷积会所见数据尺寸，在卷积神经网络中我们有时需要数据尺寸不要减小太快，这时使用的手段就是“Padding”，通过在原始数据上增加padding数据来扩展数据然后再进行卷积计算。\n",
    "\n",
    "进行“Padding”示意如下，使用元素“1”进行填充，填充尺寸$p=1$：\n",
    "\n",
    "![](./data/image/padding.jpg 'Padding')\n",
    "\n",
    "原本形状为$(m, n)$的数据进行尺寸为$p$的填充后形状为$(m+2p, n+2p)$。\n",
    "\n",
    "### Valid&Same\n",
    "\n",
    "有了“Padding”手段后我们可以先进行数据填充，然后在进行卷积运算，实际使用较多的为两种：\n",
    "\n",
    "* Valid Convolution: 即不进行数据填充直接进行卷积运算\n",
    "* Same Convolution: 首先以进行卷积后数据尺寸不变的目的进行填充，然后进行卷积运算\n",
    "\n",
    "\n",
    "### 2D&3D\n",
    "\n",
    "* 前面用来描述卷积概念的例子实际就是2D维度的卷积，一维卷积则更加简单，如最开始的数学描述，只是更改求和域。\n",
    "* 3D维度的卷积则如下图所示，其中卷积函数与被卷积数据第三维度必须相同，卷积计算结果则需要进行3个维度的全部元素的求和。\n",
    "\n",
    "![](./data/image/conv7.jpg 'Padding')\n",
    "\n",
    "## 后向过程\n",
    "\n",
    "### **$dA_{prev}：$**\n",
    "\n",
    "这里的求解过程全部以前向过程引入了多少变化权重此处就需传播多少的角度来理解就直观很多，如下图计算卷积过程中每一个卷积窗与卷积核对应相乘后再相加得到一步卷积结果，那么卷积窗中元素变化能被传播到后层的大小即为卷积核对应位置的系数，所以在前向传播中我们只需要将$dZ$的每个元素与卷积核相乘放入卷积窗的位置最后得到即为前一层输入的后向传播结果$dA_{prev}$。\n",
    "\n",
    "![](./data/image/conv8.jpg 'Padding')\n",
    "\n",
    "$$z = \\sum_{i=1}^{3} \\sum_{j=1}^{3} x_{ij}w_{ij}$$\n",
    "\n",
    "$$\\frac{dz}{dx} = W$$\n",
    "\n",
    "以上为一步卷积的前向传播推导，整个卷积其实就是重复这个过程，知道将全部卷积窗计算完成。\n",
    "\n",
    "### **$dW：$**\n",
    "\n",
    "根据前面的计算结果，可以得出\n",
    "\n",
    "$$\\frac{dz}{dW} = x$$\n",
    "\n",
    "计算W的前向传播我们只需要将对应后一层误差的对应的卷积结果位置与卷积核的元素相乘放入对应位置即可。\n",
    "\n",
    "### **$db：$**\n",
    "\n",
    "$$\\frac{dz}{db} = 1$$\n",
    "\n",
    "由于在相对与一组数据和卷积核的计算过程中只使用一个标量的偏置，也就是所谓的“权值共享”,即将偏置广播倒每一个卷积结果中，那么求解$db$时其实就是将与$b$对应的卷积结果位置的误差求和。\n",
    "\n",
    "\n",
    "# 2、Pooling\n",
    "\n",
    "## 前向过程\n",
    "\n",
    "单步\"Pooling\"操作如图所示是一个下采样过程，不同模式下以不同的规则对范围内特征进行采样，常用的有“Max”和“Mean”两种：\n",
    "\n",
    "![](./data/image/pool1.jpg 'pool')\n",
    "\n",
    "这里将原始数据的形状记为$(n_h, n_w, n_c)$，采样窗口的形状记为$(n_{fh}, n_{fw})$，$s$为采样步长，$n_c$表示数据深度（例如图片即可为其不同颜色通道），不同深度的采样单独进行，采样结束后的结果形状为$(\\frac{n_h - n_{fh}}{s} + 1, \\frac{n_w - n_{fw}}{s} + 1, n_c)$\n",
    "\n",
    "## 后向过程\n",
    "\n",
    "如前所述“Pooling”的前向过程为一个采样操作，那么后向过程我们来计算这个采样过程引入的误差：\n",
    "\n",
    "![](./data/image/pool2.jpg 'pool backward')\n",
    "\n",
    "* Max\n",
    "  根据前向过程，我们只取了采样窗中的最大值作为采样结果，那么在后向传播误差的过程中也就只有采样位置的最大值起到了作用，所以其他部分填0，采样结果位置填最大值，即为传播因子。\n",
    " \n",
    "* Mean\n",
    "  根据前向过程，我们只取了采样窗中的全部样本均值作为采样结果，那么在后向传播误差的过程中每个位置起到的作用也就是采样结果对采样窗口的尺寸求平均，所以采样窗口位置填前向结果与采样窗口尺寸的比值。\n",
    "\n",
    "\n",
    "# 3、FC\n",
    "\n",
    "“full-conection”的存在其实就是为了将多维数据转换为单维数据，然后进行标签化等等操作，具体过程如下,对应到代码就是numpy中的flatten操作：\n",
    "\n",
    "![](./data/image/fc1.jpg 'pool')\n",
    "\n",
    "FC层只将数据进行了变形，而未引入任何有效误差，所以求解这一步的反向过程只需将后一层的误差根据原始数据的形状进行排列即可。\n",
    "\n",
    "\n",
    "# 4、softmax\n",
    "\n",
    "这是直接给出softmax的表达式，至于为何使用softmax而不是直接对数据进行归一化的讨论话题很多不再赘述，一个比较明显的优势就在于指数形式更便于做计算优化。\n",
    "\n",
    "$$y = softmax(x)$$\n",
    "$$y_i = \\frac{e^{x_i}}{\\sum_{j=1}^{n} e^j}$$\n",
    "\n",
    "这里同时给出softmax函数的求导结果，\n",
    "\n",
    "$$\\frac{dy}{dx} = \\begin{bmatrix} \\frac{dy_1}{dx_1} & \\cdots & \\frac{dy_1}{dx_n} \\\\ \\vdots & \\ddots & \\vdots \\\\ \\frac{dy_n}{dx_1} & \\cdots & \\frac{dy_n}{dx_n} \\end{bmatrix}$$\n",
    "\n",
    "设$s = \\sum_{j=1}^{n} e^{x_j}$，则$y_i = \\frac{e^{x_i}}{s}$, \n",
    "\n",
    "$$\\frac{dy_i}{dx_j} = \\frac{d}{dx_j} \\frac{e^{x_i}}{s}$$\n",
    "$$= \\frac{d}{dx_j} \\frac{e^{x_i}}{s}$$\n",
    "$$= \\frac{(e^{x_i})^{'}s - e^{x_i}s^{'}}{s^2}$$\n",
    "\n",
    "当$i = j$时：\n",
    "\n",
    "$$= \\frac{(e^{x_i})s - e^{x_i}e^{x_i}}{s^2}$$\n",
    "$$= \\frac{e^{x_i}}{s} (1 - \\frac{e^{x_i}}{s})$$\n",
    "\n",
    "当$i \\ne j$时：\n",
    "\n",
    "$$= \\frac{0 - e^{x_i}e^{x_j}}{s^2}$$\n",
    "$$= -\\frac{e^{x_i}}{s} \\frac{e^{x_j}}{s}$$\n",
    "\n",
    "$$\\frac{dy}{dx} = \\begin{bmatrix} y_1(1-y_1) & -y_1y_2 & \\cdots & -y_1y_n \\\\ -y_2y_1 & y_2(1-y_2) & \\cdots & -y_2y_n \\\\ \\vdots & \\vdots &\\ddots & \\vdots \\\\ -y_ny_1 & -y_ny_2 & \\cdots & y_n(1-y_n) \\end{bmatrix}$$\n",
    "\n",
    "# 5、Loss\n",
    "\n",
    "典型的卷积神经网络最后将问题归结为一个最大似然问题，网络计算得到的结果记作$\\widehat{y}$，实际结果为$y$\n",
    "\n",
    "$$loss = \\frac{1}{m} \\sum_{i=1}^{m} \\widehat{y}^{i} log^{y^{i}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "if not os.getcwd() in sys.path:\n",
    "    sys.path.append(\"%s/..\" % os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from arsenal.data_process.load_data import DataLoader\n",
    "from arsenal.data_process.plot_data import Ploter\n",
    "from arsenal.optimizer.grad_descent import GradDescent\n",
    "from arsenal.model.cnn import ConvolutionNeuralNetwork\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试初始化函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2, 3, 2)\n",
      "(1, 1, 1, 2)\n",
      "(2, 2, 2, 2)\n",
      "(1, 1, 1, 2)\n",
      "(10, 9, 9, 2)\n",
      "(10, 3, 3, 2)\n"
     ]
    }
   ],
   "source": [
    "from config.map import test_initialize_map\n",
    "\n",
    "np.random.randn(1)\n",
    "\n",
    "X = np.random.rand(10,20,20,3)\n",
    "test_initialize_map['L0']['cache']['A'] = X\n",
    "\n",
    "CNN = ConvolutionNeuralNetwork(test_initialize_map)\n",
    "\n",
    "CNN.initialize(end=len(test_initialize_map.keys())-1, seed=1)\n",
    "\n",
    "print(CNN.map['L1']['cache']['W'].shape)\n",
    "print(CNN.map['L1']['cache']['b'].shape)\n",
    "print(CNN.map['L2']['cache']['W'].shape)\n",
    "print(CNN.map['L2']['cache']['b'].shape)\n",
    "print(CNN.map['L1']['cache']['A'].shape)\n",
    "print(CNN.map['L2']['cache']['A'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试pad函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape:  (4, 3, 3, 2)\n",
      "X padded shape:  (4, 7, 7, 2)\n",
      "X[1,1] = [[ 0.90085595 -0.68372786]\n",
      " [-0.12289023 -0.93576943]\n",
      " [-0.26788808  0.53035547]]\n",
      "X_pad[1,1] = [[ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]\n",
      " [ 0.  0.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAADHCAYAAADxqlPLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x242c43ad8d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "map = {}\n",
    "\n",
    "CNN = ConvolutionNeuralNetwork(map)\n",
    "\n",
    "X = np.random.randn(4,3,3,2)\n",
    "X_pad = CNN.pad(X, n_pad=2, val=0)\n",
    "\n",
    "print(\"X shape: \", X.shape)\n",
    "print(\"X padded shape: \", X_pad.shape)\n",
    "print (\"X[1,1] =\", X[1,1])\n",
    "print (\"X_pad[1,1] =\", X_pad[1,1])\n",
    "\n",
    "fig, axarr = plt.subplots(1,2)\n",
    "axarr[0].set_title('X')\n",
    "axarr[0].imshow(X[0, :, :, 0])\n",
    "axarr[1].set_title('X padded')\n",
    "axarr[1].imshow(X_pad[0, :, :, 0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试pool函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mode = max\n",
      "X_pool = [[[[ 1.74481176  0.86540763  1.13376944]]]\n",
      "\n",
      "\n",
      " [[[ 1.13162939  1.51981682  2.18557541]]]]\n",
      "\n",
      "mode = average\n",
      "X_pool = [[[[ 0.02105773 -0.20328806 -0.40389855]]]\n",
      "\n",
      "\n",
      " [[[-0.22154621  0.51716526  0.48155844]]]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "map = {}\n",
    "\n",
    "CNN = ConvolutionNeuralNetwork(map)\n",
    "\n",
    "X = np.random.randn(2, 4, 4, 3)\n",
    "\n",
    "stride = 2\n",
    "f_shape = (3,3)\n",
    "\n",
    "X_pool = CNN.pool_forward(X, f_shape, stride)\n",
    "print(\"mode = max\")\n",
    "print(\"X_pool =\", X_pool)\n",
    "print()\n",
    "\n",
    "X_pool = CNN.pool_forward(X, f_shape, stride, mode=\"average\")\n",
    "print(\"mode = average\")\n",
    "print(\"X_pool =\", X_pool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 测试convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z's mean = 0.0489952035289\n",
      "Z[3,2,1] = [-0.61490741 -6.7439236  -2.55153897  1.75698377  3.56208902  0.53036437\n",
      "  5.18531798  8.75898442]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "map = {}\n",
    "A_prev = np.random.randn(10,4,4,3)\n",
    "W = np.random.randn(2,2,3,8)\n",
    "b = np.random.randn(1,1,1,8)\n",
    "stride = 2\n",
    "pad = 2\n",
    "val = 0\n",
    "CNN = ConvolutionNeuralNetwork(map)\n",
    "\n",
    "Z = CNN.convolution_forward(A_prev, W, b, stride, pad, val)\n",
    "print(\"Z's mean =\", np.mean(Z))\n",
    "print(\"Z[3,2,1] =\", Z[3,2,1])\n",
    "\n",
    "\n",
    "# # Give A_prev 1 training example and 1 channel, so that\n",
    "# # A_prev.shape = (1, n_H_prev, n_W_prev, 1)\n",
    "# # n_H_prev and n_W_prev can be anything, \n",
    "# # as can any elements of A_prev\n",
    "# n_H_prev = 5\n",
    "# n_W_prev = 7\n",
    "# A_prev = np.arange(n_H_prev*n_W_prev) + 1\n",
    "# A_prev = A_prev.reshape((1, n_H_prev, n_W_prev, 1))\n",
    "\n",
    "# # Make W a single 1-channel, 3x3 filter of all zeros,  \n",
    "# # except for a 1 in the center\n",
    "# W = np.zeros((3,3,1,1))\n",
    "# W[1,1,0,0] = 1\n",
    "\n",
    "# # Zero out b, with the appropriate dimensionality\n",
    "# b = np.zeros((1,1,1,1))\n",
    "\n",
    "# # Same padding: f = 3 ==> pad = (f-1)/2 = 1, stride = 1\n",
    "# hparameters = {\"pad\":1, \"stride\":1}\n",
    "\n",
    "# # Run conv_forward()\n",
    "# Z, cache_conv = conv_forward(A_prev, W, b, hparameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 测试pool_backward函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mode = max\n",
      "mean of dA =  0.145713902729\n",
      "dA_prev[1,1] =  [[ 0.          0.        ]\n",
      " [ 5.05844394 -1.68282702]\n",
      " [ 0.          0.        ]]\n",
      "\n",
      "mode = average\n",
      "mean of dA =  0.145713902729\n",
      "dA_prev[1,1] =  [[ 0.08485462  0.2787552 ]\n",
      " [ 1.26461098 -0.25749373]\n",
      " [ 1.17975636 -0.53624893]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "map = {}\n",
    "\n",
    "CNN = ConvolutionNeuralNetwork(map)\n",
    "\n",
    "A_prev = np.random.randn(5, 5, 3, 2)\n",
    "stride = 1\n",
    "f_shape = (2, 2)\n",
    "\n",
    "dA = np.random.randn(5, 4, 2, 2)\n",
    "#A = CNN.pool_forward(A_prev, f_shape, stride， mode='max')\n",
    "dA_prev = CNN.pool_backward(dA, A_prev, f_shape, stride, mode='max')\n",
    "print(\"mode = max\")\n",
    "print('mean of dA = ', np.mean(dA))\n",
    "print('dA_prev[1,1] = ', dA_prev[1,1])  \n",
    "print()\n",
    "dA_prev = CNN.pool_backward(dA, A_prev, f_shape, stride, mode='average')\n",
    "print(\"mode = average\")\n",
    "print('mean of dA = ', np.mean(dA))\n",
    "print('dA_prev[1,1] = ', dA_prev[1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试convolution_backward函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dA_mean = 1.45243777754\n",
      "dW_mean = 1.72699145831\n",
      "db_mean = 7.83923256462\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "map = {}\n",
    "CNN = ConvolutionNeuralNetwork(map)\n",
    "\n",
    "A_prev = np.random.randn(10,4,4,3)\n",
    "W = np.random.randn(2,2,3,8)\n",
    "b = np.random.randn(1,1,1,8)\n",
    "stride = 2\n",
    "pad = 2\n",
    "p_val = 0\n",
    "\n",
    "Z = CNN.convolution_forward(A_prev, W, b, stride, pad, val)\n",
    "#cache: A_prev, W, b, stride, pad,\n",
    "\n",
    "dA, dW, db = CNN.convolution_backward(Z, A_prev, W, b, stride, pad, p_val)\n",
    "\n",
    "print(\"dA_mean =\", np.mean(dA))\n",
    "print(\"dW_mean =\", np.mean(dW))\n",
    "print(\"db_mean =\", np.mean(db))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
