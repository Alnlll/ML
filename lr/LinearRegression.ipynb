{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "假设输入输出间为线性关系，其中$\\mathit{x} \\in \\mathbb{R}^n$,$\\mathit{w} \\in \\mathbb{R}^n$,预测输出为$\\widehat{\\mathit{y}}$。定义输出为：\n",
    "\n",
    "$$\\widehat{\\mathit{y}} = w^TX$$\n",
    "\n",
    "使用均方误差作为P来衡量模型的性能，则损失函数为（其中$\\frac{1}{2m}$的2加在常数项不影响结果）：\n",
    "\n",
    "$$loss = \\frac{1}{2m} \\sum_{i=1}^{m} (\\widehat{\\mathit{y}}^{(i)} - y^{(i)})^2$$\n",
    "\n",
    "则目标任务则为：\n",
    "\n",
    "$$argmin loss: argmin \\frac{1}{2m} \\sum_{i=1}^{m} (\\widehat{\\mathit{y}}^{(i)} - y^{(i)})^2$$\n",
    "\n",
    "可以直观的得出当$\\widehat{\\mathit{y}} - y$时loss最小，则问题可转化为\n",
    "\n",
    "$$argmin \\frac{1}{2m} ||\\widehat{\\mathit{y}} - y||_2^2$$\n",
    "\n",
    "设$Cost = \\frac{1}{2m} ||\\widehat{\\mathit{y}} - y||_2^2$，对$\\mathit{w}$求导如下：\n",
    "\n",
    "$$\\mathit{ \\frac{d}{dw}Cost = \\frac{1}{m} \\frac{d(Xw - y)^T(Xw - y)}{dw} }$$ \n",
    "\n",
    "$$\\mathit{ = \\frac{1}{2m} \\frac{d(Xw - y)^T(Xw - y)}{dw} }$$\n",
    "\n",
    "$$\\mathit{ = \\frac{1}{2m} \\frac{d(w^TX^TXw - w^TX^Ty - y^TXw + y^Ty)}{dw} }$$\n",
    "\n",
    "标量转置为其本身：\n",
    "\n",
    "$$\\mathit{ = \\frac{1}{2m} \\frac{d(w^TX^TXw - 2y^TXw + y^Ty)}{dw} }$$\n",
    "\n",
    "$$\\mathit{ \\frac{d}{dw}Cost = \\frac{1}{m} X^T(Xw - y) }$$\n",
    "\n",
    "使用梯度下降法同步更新$\\mathit{w}$：\n",
    "\n",
    "$$\\mathit{ w = w - \\alpha \\frac{d}{dw}Cost }$$\n",
    "\n",
    "其中“偏置”通过训练时在样本中增加全1个体获取。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(\"%s\\\\..\" % os.getcwd())\n",
    "\n",
    "import numpy as np\n",
    "from arsenal.data_process.plot_data import Ploter\n",
    "from arsenal.data_process.load_data import DataLoader\n",
    "from arsenal.optimizer.grad_descent import GradDescent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LinearRegression(object):\n",
    "    def __init__(self):\n",
    "        self.ploter = Ploter()\n",
    "        self.data_loader = DataLoader()\n",
    "    def lr_func(self, X, w):\n",
    "        return np.dot(X, w) #适应实际数据形式\n",
    "    def lr_cost(self, X, w, y):\n",
    "        m = X.shape[0]\n",
    "        h = self.lr_func(X, w)\n",
    "        cost = (1/2/m) * np.dot((h-y).T, h-y)\n",
    "        return cost\n",
    "    def lr_grad(self, X, w, y, m):\n",
    "        h = self.lr_func(X, w)\n",
    "        grad_w = (1/m) * np.dot(X.T, h - y)\n",
    "        return grad_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing the cost function ...\n",
      "With w = [0 ; 0], Cost computed =  [[ 32.07273388]]\n",
      "Expected cost value (approx) 32.07\n",
      "With w = [-1 ; 2], Cost computed =  [[ 54.24245508]]\n",
      "Expected cost value (approx) 54.24\n",
      "Iteration: 0, Cost: 6.737190\n",
      "Iteration: 10, Cost: 5.859828\n",
      "Iteration: 20, Cost: 5.810818\n",
      "Iteration: 30, Cost: 5.763545\n",
      "Iteration: 40, Cost: 5.717947\n",
      "Iteration: 50, Cost: 5.673965\n",
      "Iteration: 60, Cost: 5.631543\n",
      "Iteration: 70, Cost: 5.590623\n",
      "Iteration: 80, Cost: 5.551154\n",
      "Iteration: 90, Cost: 5.513084\n",
      "Iteration: 100, Cost: 5.476363\n",
      "Iteration: 110, Cost: 5.440943\n",
      "Iteration: 120, Cost: 5.406779\n",
      "Iteration: 130, Cost: 5.373825\n",
      "Iteration: 140, Cost: 5.342040\n",
      "Iteration: 150, Cost: 5.311381\n",
      "Iteration: 160, Cost: 5.281808\n",
      "Iteration: 170, Cost: 5.253284\n",
      "Iteration: 180, Cost: 5.225771\n",
      "Iteration: 190, Cost: 5.199232\n",
      "Iteration: 200, Cost: 5.173635\n",
      "Iteration: 210, Cost: 5.148944\n",
      "Iteration: 220, Cost: 5.125129\n",
      "Iteration: 230, Cost: 5.102157\n",
      "Iteration: 240, Cost: 5.080000\n",
      "Iteration: 250, Cost: 5.058628\n",
      "Iteration: 260, Cost: 5.038013\n",
      "Iteration: 270, Cost: 5.018129\n",
      "Iteration: 280, Cost: 4.998950\n",
      "Iteration: 290, Cost: 4.980450\n",
      "Iteration: 300, Cost: 4.962606\n",
      "Iteration: 310, Cost: 4.945395\n",
      "Iteration: 320, Cost: 4.928794\n",
      "Iteration: 330, Cost: 4.912780\n",
      "Iteration: 340, Cost: 4.897335\n",
      "Iteration: 350, Cost: 4.882437\n",
      "Iteration: 360, Cost: 4.868067\n",
      "Iteration: 370, Cost: 4.854206\n",
      "Iteration: 380, Cost: 4.840836\n",
      "Iteration: 390, Cost: 4.827940\n",
      "Iteration: 400, Cost: 4.815501\n",
      "Iteration: 410, Cost: 4.803504\n",
      "Iteration: 420, Cost: 4.791931\n",
      "Iteration: 430, Cost: 4.780768\n",
      "Iteration: 440, Cost: 4.770001\n",
      "Iteration: 450, Cost: 4.759616\n",
      "Iteration: 460, Cost: 4.749599\n",
      "Iteration: 470, Cost: 4.739937\n",
      "Iteration: 480, Cost: 4.730617\n",
      "Iteration: 490, Cost: 4.721627\n",
      "Iteration: 500, Cost: 4.712956\n",
      "Iteration: 510, Cost: 4.704593\n",
      "Iteration: 520, Cost: 4.696526\n",
      "Iteration: 530, Cost: 4.688744\n",
      "Iteration: 540, Cost: 4.681239\n",
      "Iteration: 550, Cost: 4.673999\n",
      "Iteration: 560, Cost: 4.667017\n",
      "Iteration: 570, Cost: 4.660281\n",
      "Iteration: 580, Cost: 4.653784\n",
      "Iteration: 590, Cost: 4.647518\n",
      "Iteration: 600, Cost: 4.641474\n",
      "Iteration: 610, Cost: 4.635643\n",
      "Iteration: 620, Cost: 4.630020\n",
      "Iteration: 630, Cost: 4.624596\n",
      "Iteration: 640, Cost: 4.619364\n",
      "Iteration: 650, Cost: 4.614317\n",
      "Iteration: 660, Cost: 4.609449\n",
      "Iteration: 670, Cost: 4.604754\n",
      "Iteration: 680, Cost: 4.600226\n",
      "Iteration: 690, Cost: 4.595857\n",
      "Iteration: 700, Cost: 4.591644\n",
      "Iteration: 710, Cost: 4.587580\n",
      "Iteration: 720, Cost: 4.583660\n",
      "Iteration: 730, Cost: 4.579878\n",
      "Iteration: 740, Cost: 4.576231\n",
      "Iteration: 750, Cost: 4.572713\n",
      "Iteration: 760, Cost: 4.569320\n",
      "Iteration: 770, Cost: 4.566047\n",
      "Iteration: 780, Cost: 4.562890\n",
      "Iteration: 790, Cost: 4.559845\n",
      "Iteration: 800, Cost: 4.556908\n",
      "Iteration: 810, Cost: 4.554075\n",
      "Iteration: 820, Cost: 4.551342\n",
      "Iteration: 830, Cost: 4.548707\n",
      "Iteration: 840, Cost: 4.546164\n",
      "Iteration: 850, Cost: 4.543712\n",
      "Iteration: 860, Cost: 4.541347\n",
      "Iteration: 870, Cost: 4.539065\n",
      "Iteration: 880, Cost: 4.536864\n",
      "Iteration: 890, Cost: 4.534742\n",
      "Iteration: 900, Cost: 4.532694\n",
      "Iteration: 910, Cost: 4.530719\n",
      "Iteration: 920, Cost: 4.528814\n",
      "Iteration: 930, Cost: 4.526977\n",
      "Iteration: 940, Cost: 4.525205\n",
      "Iteration: 950, Cost: 4.523495\n",
      "Iteration: 960, Cost: 4.521847\n",
      "Iteration: 970, Cost: 4.520256\n",
      "Iteration: 980, Cost: 4.518722\n",
      "Iteration: 990, Cost: 4.517242\n",
      "Iteration: 1000, Cost: 4.515815\n",
      "Iteration: 1010, Cost: 4.514438\n",
      "Iteration: 1020, Cost: 4.513111\n",
      "Iteration: 1030, Cost: 4.511830\n",
      "Iteration: 1040, Cost: 4.510594\n",
      "Iteration: 1050, Cost: 4.509403\n",
      "Iteration: 1060, Cost: 4.508253\n",
      "Iteration: 1070, Cost: 4.507145\n",
      "Iteration: 1080, Cost: 4.506075\n",
      "Iteration: 1090, Cost: 4.505044\n",
      "Iteration: 1100, Cost: 4.504049\n",
      "Iteration: 1110, Cost: 4.503089\n",
      "Iteration: 1120, Cost: 4.502164\n",
      "Iteration: 1130, Cost: 4.501271\n",
      "Iteration: 1140, Cost: 4.500409\n",
      "Iteration: 1150, Cost: 4.499579\n",
      "Iteration: 1160, Cost: 4.498778\n",
      "Iteration: 1170, Cost: 4.498005\n",
      "Iteration: 1180, Cost: 4.497259\n",
      "Iteration: 1190, Cost: 4.496540\n",
      "Iteration: 1200, Cost: 4.495847\n",
      "Iteration: 1210, Cost: 4.495178\n",
      "Iteration: 1220, Cost: 4.494533\n",
      "Iteration: 1230, Cost: 4.493910\n",
      "Iteration: 1240, Cost: 4.493310\n",
      "Iteration: 1250, Cost: 4.492731\n",
      "Iteration: 1260, Cost: 4.492172\n",
      "Iteration: 1270, Cost: 4.491633\n",
      "Iteration: 1280, Cost: 4.491114\n",
      "Iteration: 1290, Cost: 4.490613\n",
      "Iteration: 1300, Cost: 4.490129\n",
      "Iteration: 1310, Cost: 4.489663\n",
      "Iteration: 1320, Cost: 4.489213\n",
      "Iteration: 1330, Cost: 4.488779\n",
      "Iteration: 1340, Cost: 4.488361\n",
      "Iteration: 1350, Cost: 4.487957\n",
      "Iteration: 1360, Cost: 4.487568\n",
      "Iteration: 1370, Cost: 4.487192\n",
      "Iteration: 1380, Cost: 4.486830\n",
      "Iteration: 1390, Cost: 4.486481\n",
      "Iteration: 1400, Cost: 4.486143\n",
      "Iteration: 1410, Cost: 4.485818\n",
      "Iteration: 1420, Cost: 4.485505\n",
      "Iteration: 1430, Cost: 4.485202\n",
      "Iteration: 1440, Cost: 4.484911\n",
      "Iteration: 1450, Cost: 4.484629\n",
      "Iteration: 1460, Cost: 4.484358\n",
      "Iteration: 1470, Cost: 4.484096\n",
      "Iteration: 1480, Cost: 4.483844\n",
      "Iteration: 1490, Cost: 4.483600\n",
      "Theta found by gradient descent:\n",
      "w:  [[-3.63029144]\n",
      " [ 1.16636235]]\n",
      "Expected theta values (approx):\n",
      " -3.6303\n",
      "  1.1664\n",
      "\n",
      "For population = 35,000, we predict a profit of  4519.7678677017675\n",
      "[[ 1  5]\n",
      " [ 1 24]] [[  2.20152031]\n",
      " [ 24.36240497]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3Xu8VXP+x/HXJ11IUSlUJCW3XIoj\nl1BuCePO0G/cJqT5ybjMGBTOESKXCYORwsS4DOMyfjFDjIQZl6JUjtRpipSUqFy6nu/vj+8+03bs\nffba17X23u/n47EfZ6911l7r0z67z/mez/eyzDmHiIgUv0ZhByAiIrmhhC4iUiKU0EVESoQSuohI\niVBCFxEpEUroIiIlQgldRKREKKGLiJQIJXQRkRLRuJAXa9u2revcuXMhLykiUvSmTJmy1DnXLtVx\nBU3onTt3ZvLkyYW8pIhI0TOz+UGOS1lyMbNtzew1M6s2s5lmdnFsf5WZfW5mU2OPo7MNWkREMhek\nhb4O+I1z7n0zawlMMbMJse+Ncs7dlr/wREQkqJQJ3Tm3CFgUe77SzKqBjvkOTERE0pPWKBcz6wz0\nBN6J7RpiZh+a2YNm1jrHsYmISBoCJ3QzawE8DVzinFsB/BHoCvTAt+BvT/K6QWY22cwmL1myJAch\ni4hIIoESupk1wSfzR51zzwA45xY759Y752qBMUCvRK91zt3vnKtwzlW0a5dy1I2IiGQoyCgXAx4A\nqp1zv4/b3z7usBOBGbkPT0Sk+K1bV5jrBGmh9wbOBA6tN0TxFjObbmYfAocAl+YzUBGRnKmqKshl\namvhiSdg553hlVfyfz0r5D1FKyoqnCYWiUjozCCPuc85ePlluOoq+OADv++003xyz4SZTXHOVaQ6\nTmu5iIjk0Ntvw6GHQv/+Ppl37AhjxsCf/5z/ayuhi0h5qKryLXMzv133PEfll48+ghNPhP33h4kT\noXVruPVWmD0bzjsPGhdgoRWVXESk/OSw5PLpp/53wrhxvmbevDlccglcfjm0apWTSwQuuRR0cS4R\nkVKxdCmMGAH33ANr1vgW+ODBcPXV0L596tfngxK6iJSfysqMX/rttzBqlC+nrFzp9w0YANdfD127\n5ii+DCmhi0j5yaBuvmYNjB4NN9wAX37p9x11lG+l9+iR2/AypYQuItKA9evh8cfhmmtg3jy/b7/9\n4OaboU+fUEP7CSV0EZEEnIMXXoChQ2H6dL9v1119i/y44zYMlokSJXQRkXrefNNPCnrzTb/dqRMM\nHw5nnAEbbRRubA3ROHQRSa1AU+XDNn06HHssHHSQT+Zt2/oO0Fmz4Oyzo53MQQldRIK47rqwI8ir\n//wHzjoL9twTxo+HFi38QJiaGj+mfOONw44wGJVcRKRsLV4MN94I990Ha9dCkybwq1/BsGGw5ZZh\nR5c+tdBFJLE8T5UP04oVvgXetSv84Q9+eduzzoJPPoE77yzOZA6a+i8iQeR5dcJCWbUK/vhH3yr/\n6iu/79hj/fbuu4cbW0M09V9EJGb9enjkEd8q//RTv+/AA/1Y8t69w40tl1RyEZHUspgqn1QBSjfO\nwXPPwR57wC9/6ZP57rv7js9Jk0ormYNKLiISljyXcV5/Ha680q9PDrD99n69lQEDoFGRNWVVchGR\nsvTBB3525z/+4be33NJP2x80CJo2DTe2fCuy31MiUtTyOHJmzhzf+t5rL5/MW7b0LfKaGhgypPST\nOajkIiJhyVHJZdEin7jHjPHDD5s1gwsv9FP327bNQZwRoJKLiJS0b76BW26BO+6AH37wdfGBA33/\nbadOYUcXDpVcRCQclZUZlVp++MHfXKJLF7jpJr994okwYwY88ED5JnNQyUVEwpRG2WXdOnjoIb+s\nzOef+319+/qx5Pvum78Qo0AlFxEpCc7B00/79VU++cTv69nTJ/IjjojmuuRhUclFRAorjZEur7wC\nvXrBqaf6ZL7DDvDEEzB5MvTrp2Ren0ouIhKeJCWXyZP9KJVXXvHb7dv7kvvAgX5FxHKjkouIFJ1Z\ns+Dqq+Gvf/Xbm2/uZ3v++tfQvHm4sRWDlCUXM9vWzF4zs2ozm2lmF8f2tzGzCWY2O/a1df7DFZGS\nElsjZsECP5Oze3efzDfeGK64AubO9QldyTyYIDX0dcBvnHO7APsBF5rZrsCVwKvOuW7Aq7FtEZHA\nlv26it/9Drp18xODwCf2OXN8p2ebNuHGV2xSllycc4uARbHnK82sGugIHA/0jR02DpgIXJGXKEWk\npHz3Hdx1F4wcCcuX+30//7mf8bnjjuHGVszSqqGbWWegJ/AOsFUs2eOcW2RmRXqPDxEplLVrYexY\nGD4cvvjC7zviCBgxAipSdvlJKoETupm1AJ4GLnHOrbCA44XMbBAwCKBTOU/hEiljtbXw5JO+w7Om\nxu/bZx8/0/Oww8KNrZQEGoduZk3wyfxR59wzsd2Lzax97PvtgS8TvdY5d79zrsI5V9GuXbtcxCwi\nRcI5v/Lh3nv7lRBramCnnXzH5zvvKJnnWpBRLgY8AFQ7534f963ngbNjz88G/pb78ESkWL39Nhxy\nCBx1FEydCh07+nLLjBlw8smaFJQPQUouvYEzgelmNjW2byhwM/CkmZ0LfAqcmp8QRaSYfPSRn6b/\n3HN+u3Vrf8OJCy+ETTYJN7ZSF2SUy5tAst+l+oNJRACYP9/P3n/4YV8zb94cLr0UfvtbaNUq7OjK\ng2aKikhWlizxo1TuvRfWrIHGjWHwYH/bt623Dju68qKELiIZWbkSRo2C227zzwH+53/8kMSuXcON\nrVwpoYtIWlavhtGj4YYbfOscfMfniBHQo0e4sZU7JXQRCWT9enjsMbj2Wpg3z+/bf38/lrxPn1BD\nkxgldBFpkHMwfrwfqTJjht/XvbtvkR97rIYfRokSuogk9eabfrXDt97y2506+Rr5GWfARhuFG5v8\nlBK6iPzEhx/6FvkLL/jttm39tP3Bg6FZs3Bjk+R0CzoR+a+5c+HMM33n5gsvQIsWfsnymhq4+OKI\nJfMEt6wrd0roIsLixXDRRbDzzvDnP/ux5Bdf7BN5VRVstlnYESZw3XVhRxA5KrmIlLHly+H22+H3\nv/drlJvBWWf5XNm5c9jRSbrKr4WuP9NEWLXKJ/GuXf1NJb77Do47ztfOx42LcDKvqvK/deqG1tQ9\n1/9rAMwluON2vlRUVLjJkycX7HoJJbnLuEg5WLcOHnnE18U/+8zvO/BAf7u33r3DjS1tZfR/2cym\nOOdS3gJEJReRMuCcX/1w2DCorvb79tjDTwo66iiNJS8V5VFy0Z9pUsYmTvQzOk86ySfz7bf3HZ8f\nfABHH13EybyyMuwIIkclF5ES9f77fiz5Sy/57S239NP2zz8fmjZN82RVVWoAhShoyaU8WugiZWTO\nHDj9dH/bt5de8kMOr7/eD0G88MIMkjloiGCRKL8auv5MkxK1cKFP3GPH+s7PZs1gyBA/db9t27Cj\nk0Iovxa6/myUEvPNN3DVVbDDDnDfff5uQQMHwuzZfq3yjJO5+p6KTvnV0EVKxPffw913+yGHX3/t\n9510kl+nfJddcnwx9T2FSsMWRUrUunXw4IO+rL1wod93yCF+COK++4Ybm4RLCV2kSNTWwtNP+1UP\nP/nE7+vZ07fQjzgiz8MP1fdUFJTQRYrAhAm+Tj5lit/eYQe48UY45RRoVIieMNXNi4ISukiEvfee\nT+Svvuq327f3jeWBA6FJk3Bjk+hRQheJoI8/9qWVp5/2261a+eGHF10EzZuHG5tElxK6SIQsWOCr\nGw895GvmG2/s1yW/4gpo3Trs6CTqym8cukgE68FffQWXX+5r4w884Ds4L7jAz/q8+WYlcwlGCV3K\nT4SmsX/3ne/c7NLFTwJavRpOOw0++shPEurYMewIpZio5CISgjVr/BT94cP97d8A+vWDESP8Giwi\nmUjZQjezB83sSzObEbevysw+N7OpscfR+Q1TJEsRmcZeWwuPPeZncl54oU/mvXr5USwvvaRkLtlJ\nOfXfzA4GvgUeds7tFttXBXzrnLstnYtp6r9EQgjT2J2Df/zDD0GcNs3v23lnX2458cQiXpNcCiJn\ny+c65yYBy3ISlUgZ+ve/oW9ffzOJadNgm218x+f06X7tFSVzyZVsOkWHmNmHsZKM+uClcLItkxRo\nGvvMmXDCCXDAATBpErRp4zs+Z8/2E4MaqwdLcizQaotm1hkYH1dy2QpYCjjgeqC9c25gktcOAgYB\ndOrUae/58+fnJHApYxFf+W/+fP874+GHfZjNm8Nll8Fvfwubbx52dFKM8nrHIufcYufceudcLTAG\n6NXAsfc75yqccxXt2rXL5HIiRWHJErj0UthxRxg3DjbayHd81tT4G08omUu+ZZTQzax93OaJwIxk\nx4rkRERGqSSycqUf2t6lC9xxB6xdC7/4Bcya5dcr33rrsCOUchFklMvjQF+gLbAYqIxt98CXXOYB\nFzjnFqW6mEa5SE5EpOSyejWMHu1vKLFkid939NF+LPmee4Ybm5SWnN3gwjk3IMHuBzKKSqQErF8P\njz4K117r6+XgOz5vugkOPjjc2KS8qZ9dik9IN1twDsaPh6FDYUasyNi9u0/kP/uZhh9K+LSWS5RE\noB5cFEJ4n954Aw48EI47zifz7bbzHZ/TpsGxxyqZSzQooUdJhBaNEu/DD+GYY3wp5V//gnbt4M47\nfYfnWWf5kSwiUaGELtEW0l8tc+fCGWdAjx7w4ovQooUPpaYGfv1raNYslLBEGqSEHrYID8eLhAL/\n1bJ4MQwZ4tdZefRRf5u3Sy7xCb6yElq2LGg4ImkJNFM0VzRsMYWIDMeLlAK9J8uX+2n5o0b5NcrN\nfEmlqgo6d8775UUalNeZoiJ5VcC/Wlatgttv95OCbrjBJ/Pjj/e18z/9SclciouGLUZJSMPxIqeq\nakPyzlMLfd06v9ZKZaW/jyfAQQf5270dcEDOLydSEEroUaK6ed45B88+C8OGwccf+3177unHkvfv\nr+GHUtyU0CXacvhXy2uvwZVXwrvv+u0uXfyiWaefDo1UfJQSoIQu0ZaDv1ref9/fKejll/32Vlv5\nafvnnQdNm2Z9epHIUEKXkjV7NlxzDfzlL357s83gd7/zwxA33TTc2ETyQQldSs7ChTB8OIwd6xfS\natYMLrrIl1u22CLs6ETyR5XDYqUO1J/4+mtfWtlhB7+srXNw7rm+pX7rrVkkc73XUiSU0MMWnyzS\nSRxa9+W/vv8eRo70nZw33ww//AAnn+zv6Tl2LGy7bZYX0HstRUIJPah8tdLik4USR1rWroX774du\n3Xw55Ztv4NBD4Z134K9/9dP3RcqJEnpQUUi2WvcFgNpaePJJvxb5BRf4mvlee/lRLK+8Ar2S3uE2\nDXqvpQhpLZegcjljsaoq9S+IysqGk0cZrvvinE/YV10FU6b4fd26wY03+hJL3saSl+F7LdGitVxy\nIV+ttKoqnyDqkkSi52oJ/si778Lhh0O/fj6Zd+jgOz5nzoRTT9XEIBHQsMWGFWBNkYyVybovH3/s\np+k/84zfbtXKt9CHDIHmzQsURJm811L8lNDDFp8s0kkcJd6C/+wzX5V66CFfM99kE7j4Yj8xqHXr\nAgdT4u+1lA4l9KDy1UrLdNhiifrqK79Q1t13w+rV/hZvgwf7GZ8dOoQdnUi0KaEHpWSbV999B3fc\nAbfcAitW+H2nneYXz+rWLdzYRIqFErqEas0aGDPGJ+7Fi/2+I4+EESP8UEQRCU4JXUJRWwtPPOFL\nKXPn+n29evmZnoccEm5sIsVKCV0Kyjn4+99h6FCYNs3v23ln3yI/4QTdYEIkG0roUjD/+pcfcjhp\nkt/eZhs/kuWss6CxPokiWdN0DMm7GTP8jZd79/bJvE0bf2Pm2bNh4MAUyVyd0SKBpUzoZvagmX1p\nZjPi9rUxswlmNjv2tdAjg6UIzJ8P55wDe+wBzz/vJwJdfbWvmV92GWy8cYCTRGENHZEiEaSF/ieg\nf719VwKvOue6Aa/GtkUAWLLE3xVoxx1h3DjfAh8yxCfy66+HzTcPO0KR0pQyoTvnJgHL6u0+HhgX\nez4OOCHHcUkRWrnSN6i7dIE77/TL2/7iF376/h/+4O/lGYhWOhTJSKDVFs2sMzDeObdbbPsb51yr\nuO9/7ZxLWHYxs0HAIIBOnTrtPX/+/ByELVGyejXcdx/ccAMsXer3HXOMXwVxzz2zPHnU1tARCUFk\nVlt0zt3vnKtwzlW0a9cu35eTAlq/Hh5+GHbayZdYli6FAw7wHZ/jx+cgmYtIWjJN6IvNrD1A7OuX\nuQtJos4538m5555w9tm+83O33fy+N9+Egw7K4cW00qFIYJkm9OeBs2PPzwb+lptwJOreeAMOPNAP\nQ5w5E7bbzrfSp06FY4/Nw8Qg1c1FAgsybPFx4N/ATma2wMzOBW4GjjCz2cARse3w6T9/3kyb5uvi\nBx/sJwi1a+c7PmfNgjPP9KsihkY/dxGg1G5Bpw60nJs716+38vjj/q1t0QIuvxwuvRRatgw7uhj9\n3KXEBe0U1YRrSeiLL/yoldGjYd06aNoU/vd//Ros6tsWiabin/qvMcs5tXy5n83ZtSvcc49fFfGc\nc+CTT2DUqAglc/3cRX5CJRcBYNUqn8BHjIBlsWlkxx/vx5J37x5ubCnp5y4lTiUXCWTdOj89v6oK\nFizw+w4+2K9Lvv/+oYYmImkqrYSuMcuBOQfPPgvDhvmp+eDHld90E/TvX2TrkuvnLgKUWslFAvnn\nP/265O++67e7dPEdoKedBo2Kv1dFpOREZuq/RMeUKf5+nYcd5pP5Vlv5unl1NQwYkMNkro5JkVAo\noZeBTz7xre+KCnj5ZdhsM7jx0FepqfFDEZs2zfEFtYa5SChKq4YuP7JwIQwfDmPH+oW0mjWDiy6C\nK6+ELdoeDptqZIhIKVELvQR9/bVP2jtst5bRo30H6HnnwZw5cOutsMUWebioxoWLhE4JvYR8/z2M\nHOk7OUeOhB/WNeHkk/0iWmPGwDZjq/KXdKuq/G+Ouk72uudK6CIFo1EuJWDtWnjwQV+6XrTI7zv0\nULj5n/uwj3sv8YvyORlHE31EckqjXOoUQwsxwxhra+HJJ/1MzsGDfTLfu/1CJnA4r/7T2IfJ4ZQ+\nNC5cJBSl30IvhtZimjE6BxMm+LHk77/v93Xr5qfpn3xy3PDDhs5bVZVekk/3eBHJmaAtdCX0KEgj\nxnff9R2er73mtzt08Hn2nHOgSZPMz5vLGEUkt8q75BLWiIv652/oemnGWF3tW9/77uuTeatWvuNz\n9mw4//wEyRwSlz7iz68Wt0hpcc4V7LH33nu7goNgx1VW5v5aDV07/noNHPfpp84NHOhco0b+sE02\nce4qbnTLluUgxlTvTWVl3ViVHz9y8V6JSGDAZBcgx5ZmyaWqKvFsxcrK5K3SXJQU6p+joXPGfy/B\ncV995RfKuvtuWL3a3+Lt/PP93YM6dMwi1hTXDfQ6ESkolVwKNSY6WekknXJPXGnk22/9QlldusDt\nt/tkfvrpUP2ru/jjfeaTedDzpoox3fOISLQFacbn6hG5kkuuSwqpSi4NXG/1aufuvtu5rbbasPvI\nI52bMiXNf1M6MaZzHpVZREJDWZdc4gUdbldXUshmeF4GJZfaWn8D5muugf/8x39r3319ueWQQwJe\nJ9MYVUYRKQrlXXKJl25yzmalwPqjShqYYOOAF1+Enj3hjDN8Mt9lF3jmGfj3vxtI5inOm1aMmgAk\nUlJKv4UeVF3LvACt1rfegqv+Zz5vfLodANtu63+PnHkmNNb6lyJST2m20PPVcVc3KibPHYXTp8Nx\nx8GBB8Ibn27HFizl9tv9euW//KWSuYhkp7ha6PloPdevmefhGvPm+erGI4/4U2+6KVx2Gfzm+s3Z\n3C3P6bVEpPSUZgs9H+pq5kGH/6Xhyy/h4othxx3h4Yd9C3zIPu9Q891WDL/e2JwVuftrIGrDDqMW\nj0g5CDIUJlePjIYt5nO2Yt25ndvwtaHzBhzmt3y5P02LFv4lZs6dcYZzNTWZnS+QXJ4rF6IWj0gR\nI+CwxawSNDAPmA5MDXLBrMeh5ypJZPpLIsX1V61ybtQo59q23XDKY45xbtq0zM6X1i+tqCXQqMUj\nUsSCJvRclFwOcc71cAHqO5FRN5O0vrqO0foLWKWYWbl+PYwb50srl14KS5dC794waRKMHw977JEk\njlTDBlMNoYzabd+iFo9IuQmS9ZM98C30tkGPj0QLPVnrPN0WemWlq6117rnnnNt11w2n2I0P3f/9\nn3O1tdmHmta/N2ot4qjFI1LEKFAL3QEvm9kUMxuU5bkSy3Wrr/46L7DheRrnnHTdP+ndG044AT76\nCDp39h2fU+nBz362IdyM4lMrV0QyESTrJ3sAHWJftwSmAQcnOGYQMBmY3KlTp2x/TaU+Jt26c5DO\n0Lhzf/CBc0cdteGl7do5d1f/F9wqmiZv8edqbZgUsUVK1OIRKWIUei0XM6sCvnXO3ZbsmIKMQ09n\nHHldqzdA67emBq45YTqPz9gdgJas4LfcxqWMomXlbzacI9H1Mx3brrVWRIQCjEM3s03NrGXdc6Af\nMCPT8wXSUCdiJiWJAAtxffEFXHgh7LwzPD5jd5o29R2fNXTlWjeclm5l5tdPFE88rbUiIukI0oxP\n9AC64Mss04CZwLBUr8nb8rl5GKv+zTfODR3qXPPm/lSNGjl3zjnOzZsXO6D+MrSJxrMniqlPn+QX\nVUeiiCRAIcahp/vI63ro9RNqhr7/3rlbb3WuTZsNOfiEE5ybMaPegfH18UQJPVFsqeJLN3bVqUXK\nQtCEXlxT/xPdhLn+iJBExwWwbh2MHQvdusHll8OyZXDwwfCvgWN59lno3j3Bi8x+PFY8k5Ep2Yxq\nyWapXxEpOaWzOFeGN6hwzq9BPmwYzJrl9/Xo4W8wceSRYI1SdEwmGp9Y//i+feH11396XP17nKbb\nCapOU5GyUL6Lc6WRzF991d8d6JRTfDLv0gUeewymTIH+/RsYS16/VZ3KxIk/Hvte9zzTjlyNUxeR\nBKKf0FMlsLqvaYwImTIF+vWDww+H996DrVnEvfdCdTUMGACNhge4ZnyCri/TBBvk31DIG2CLSHEJ\nUmjP1SMvU//r72ugo3DWLOdOPXVDH+Zmmzl3443OfUvz9K4Zf510b7qcy45MjYoRKQuUZKdoEHUd\nhX37/nfX55/DBRfArrvCU0/Bxo3XcvkBbzF3xRYMHWZsyvfply7qrpPuWPFctqQ1Tl1E4hTXTc/q\nEljdLePq1JVG+vTZsO/111m2DEaOhLvuglWroFEjOO88qBy7Pdu8tQD4asPrk5VPUiXN+ARd6ASr\nMouIxAvSjM/VIy/j0OsmEMVN3vmOTdxNXOFabfz9f3efcopz1dVxr6l/jiDyebMNEZEkKPRaLkFk\nPWwx0ZDEuNb1WmvCA5zLcK5lER0AOIxXuKnnU+xzXPvE47bjW/3p0JBBESmQoMMWiyuhJ0qifftS\n+/oknuJUruYG5tANgL2ZzM0TKjj88IDnyUUsIiJ5UBbj0J2Dl66aSEXPWk7nL8yhGztusZSnnoL3\n2IfD36xq+ATZ1KDVISkiERP9hJ5kHPo7543h0EP9BKAPPoAOHeB+zmfmF2055RSwPn2ST42vS8bZ\nTJ1Xh6SIRExxJPS4iTTVHzlOOtGx3wPnM3EitG4Nt9wCc+bA+ZUdaVw3bmfixIbPKSJSYqKf0GM+\n/RQG8gC7da/l2Wdhk01g6FCYO9cvprXJJmzoNE01y1NT50WkBEW+U/SHH+Dqq+Gee2D1amjMWs7/\nVROuuQbaj65qOBGn6rhUx6aIFIGS6RRt1gxeecUn8wEDoJpduPdeaN+ehmvgadxeTkSkFEQ+oTdq\nBKP3Gcv79OSxx40dqAm20mFdsm8o6WukioiUkMgndID9xp5HT/dB4vJINjVwtd5FpIQURUIPLNk6\n5Q0lfSV1ESkRke8U/Yn46f+p7mBUp6E7GaljVEQirjSn/teXTkJPdqwSuohEXMmMcmlQfKdm/RZ4\nZeWGR33ZjEVXiUZEIqq4W+jx6pJz/L+n/rrpdeJvzqwbM4tIxJVHCz2R+Ba07r8pImWk+BJ6/YRd\nf1TLddflfiq/lgsQkSJQfCWXRCWP+sMU41vhKrmISJEr35IL+KRbl8gTlVzqjqnf4o67sbSISLEp\njoSerOSRbAmAuqSdrCSSrLb++uupY8nlcgEq2YhIDmVVcjGz/sCdwEbAWOfczQ0dn7OSC/y47FFX\nBkm2vktD9w2NL6EUupyi8o2IBJD3kouZbQTcAxwF7AoMMLNdMz1fzlRWJh7Vkqw13KePOjxFpCRk\nU3LpBcxxzs11zq0BngCOz01YCdSVXerUr3vXfa9ulEtQEycWdmijRsyISJ5kk9A7Ap/FbS+I7fsR\nMxtkZpPNbPKSJUsyv1qyuneyhBzVpXE1Nl5E8iSbhJ6oGfyTgrBz7n7nXIVzrqJdu3ZZXC5NmSTI\nqP4SEBEJIJuEvgDYNm57G2BhduEElCzxZpuQC91K1i8QEcmhbBL6e0A3M9vezJoCpwPP5yasDBVb\n2aLY4hWRSMs4oTvn1gFDgJeAauBJ59zMXAXWoIZuKyciUqYaZ/Ni59yLwIs5ikVERLJQHDNFQcP9\nRERSKL7FuSDxbFERkRJV3otzpUMtfBEpEcWV0JPNFs0mKauDVURKRHGWXCB3C1tpgSwRiTiVXBqi\nDlYRKUFZDVsMVTazLONXX1QLXURKRPG20NWaFhH5keJN6Lmi9VREpEQooaulLyIlQgldRKREFFdC\nV2taRCSp4kromgQkIpJUcSV0ERFJKvoJXZOAREQCKa6p/5oEJCJlSFP/RUTKTHEldE0CEhFJqrgS\nuurmIiJJFVdCFxGRpJTQRURKhBK6iEiJUEIXESkRSugiIiWioBOLzGwJMD/Dl7cFluYwnFxTfNlR\nfNlRfNmLcozbOefapTqooAk9G2Y2OchMqbAovuwovuwovuwVQ4ypqOQiIlIilNBFREpEMSX0+8MO\nIAXFlx3Flx3Fl71iiLFBRVNDFxGRhhVTC11ERBoQuYRuZvPMbLqZTTWznyyebt5dZjbHzD40s70K\nGNtOsbjqHivM7JJ6x/Q1s+U4nrgnAAAERUlEQVRxx1yb55geNLMvzWxG3L42ZjbBzGbHvrZO8tqz\nY8fMNrOzCxjfrWb2cezn96yZtUry2gY/C3mMr8rMPo/7GR6d5LX9zWxW7LN4ZQHj+0tcbPPMbGqS\n1xbi/dvWzF4zs2ozm2lmF8f2R+Iz2EB8kfkM5pRzLlIPYB7QtoHvHw38HTBgP+CdkOLcCPgCPz40\nfn9fYHwB4zgY2AuYEbfvFuDK2PMrgZEJXtcGmBv72jr2vHWB4usHNI49H5koviCfhTzGVwX8NsDP\nvwboAjQFpgG7FiK+et+/Hbg2xPevPbBX7HlL4BNg16h8BhuILzKfwVw+ItdCD+B44GHnvQ20MrP2\nIcRxGFDjnMt0olROOOcmAcvq7T4eGBd7Pg44IcFLjwQmOOeWOee+BiYA/QsRn3PuZefcutjm28A2\nub5uUEnevyB6AXOcc3Odc2uAJ/Dve041FJ+ZGfBz4PFcXzco59wi59z7secrgWqgIxH5DCaLL0qf\nwVyKYkJ3wMtmNsXMBiX4fkfgs7jtBbF9hXY6yf8j7W9m08zs72bWvZBBxWzlnFsE/gMNbJngmKi8\njwPxf3ElkuqzkE9DYn+OP5ikXBCF9+8gYLFzbnaS7xf0/TOzzkBP4B0i+BmsF1+8qH4G09Y47AAS\n6O2cW2hmWwITzOzjWCuljiV4TUGH6phZU+A44KoE334fX4b5NlZ7fQ7oVsj4AorC+zgMWAc8muSQ\nVJ+FfPkjcD3+/bgeX9YYWO+Y0N8/YAANt84L9v6ZWQvgaeAS59wKs0Rvz09flmBfXt7D+vHF7Y/q\nZzAjkWuhO+cWxr5+CTyL/9M23gJg27jtbYCFhYnuv44C3nfOLa7/DefcCufct7HnLwJNzKxtgeNb\nXFeGin39MsExob6PsQ6wnwG/cLFiZX0BPgt54Zxb7Jxb75yrBcYkuW7Y719j4CTgL8mOKdT7Z2ZN\n8MnyUefcM7HdkfkMJokv0p/BTEUqoZvZpmbWsu45vuNiRr3DngfOMm8/YHndn3YFlLRlZGZbx2qb\nmFkv/Hv8VQFjA/8e1Y0YOBv4W4JjXgL6mVnrWEmhX2xf3plZf+AK4Djn3PdJjgnyWchXfPF9Micm\nue57QDcz2z72F9vp+Pe9UA4HPnbOLUj0zUK9f7HP+gNAtXPu93HfisRnMFl8Uf8MZizsXtn4B37E\nwLTYYyYwLLZ/MDA49tyAe/AjDKYDFQWOsTk+QW8ety8+viGx2KfhO1sOyHM8jwOLgLX4Fs+5wBbA\nq8Ds2Nc2sWMrgLFxrx0IzIk9flnA+Obga6dTY4/7Ysd2AF5s6LNQoPgeiX22PsQnpvb144ttH40f\nNVFTyPhi+/9U95mLOzaM9+9AfJnkw7if59FR+Qw2EF9kPoO5fGimqIhIiYhUyUVERDKnhC4iUiKU\n0EVESoQSuohIiVBCFxEpEUroIiIlQgldRKREKKGLiJSI/weT7EULS2Yi3QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x203cf3f72b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if '__main__' == __name__:\n",
    "    test = LinearRegression()\n",
    "    \n",
    "    #加载数据\n",
    "    data_path = './data/ex1data1.txt'\n",
    "    data = test.data_loader.load(data_path=data_path)\n",
    "    X = data[:,0]\n",
    "    if (1 == len(X.shape)):\n",
    "        X = X.reshape(X.shape[0], 1)\n",
    "    y = data[:,1]\n",
    "    if (1 == len(y.shape)):\n",
    "        y = y.reshape(y.shape[0], 1)\n",
    "    \n",
    "    #设置初始值及超参数\n",
    "    costs = []\n",
    "    step = 10\n",
    "    iterations = 1500\n",
    "    learning_rate = 0.01\n",
    "    X_ = np.c_[np.ones((X.shape[0], 1)), X]\n",
    "    m = X_.shape[0]\n",
    "    n = X_.shape[1]\n",
    "    w = np.zeros((n, 1))\n",
    "    optimizer = GradDescent()\n",
    "    \n",
    "    #测试Cost计算\n",
    "    print(\"\\nTesting the cost function ...\")\n",
    "    Cost = test.lr_cost(X_, w, y);\n",
    "    print(\"With w = [0 ; 0], Cost computed = \", Cost);\n",
    "    print(\"Expected cost value (approx) 32.07\");\n",
    "    \n",
    "    Cost = test.lr_cost(X_, np.array(([-1], [2])), y);\n",
    "    print(\"With w = [-1 ; 2], Cost computed = \", Cost);\n",
    "    print(\"Expected cost value (approx) 54.24\");\n",
    "    \n",
    "    #测试梯度下降\n",
    "    for i in range(iterations):\n",
    "        \n",
    "        grad_w= test.lr_grad(X_, w, y, m)\n",
    "        w = optimizer.descent(grad_w, w, rate=learning_rate)\n",
    "        \n",
    "        if 0 == (i % step):\n",
    "            costs.append(test.lr_cost(X_, w, y))\n",
    "            print(\"Iteration: %d, Cost: %f\" % (i, costs[-1]))\n",
    "    print('Theta found by gradient descent:')\n",
    "    print('w: ', w)\n",
    "    print('Expected theta values (approx):')\n",
    "    print(' -3.6303\\n  1.1664\\n')\n",
    "    \n",
    "    index = np.arange(0,iterations, step).reshape(iterations//step, 1)\n",
    "    costs = np.array((costs)).reshape(len(costs),1)\n",
    "    #test.ploter.plot(index, np.array((costs)), set_str = 'r-')\n",
    "    \n",
    "    #预测结果\n",
    "    x1 = np.array(([1, 3.5]))\n",
    "    predict1 = np.dot(x1, w)\n",
    "    print(\"For population = 35,000, we predict a profit of \", float(predict1)*10000)\n",
    "    \n",
    "    index = np.array(([1, 5], [1, 24]))\n",
    "    res = np.dot(index, w)\n",
    "\n",
    "    test.ploter.plot(X, y)\n",
    "    test.ploter.plot(np.array(([5],[24])), res, set_str='b-')\n",
    "    test.ploter.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
